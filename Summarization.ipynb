{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import sample\n",
    "import time\n",
    "import re\n",
    "\n",
    "# for summarization\n",
    "from gensim.summarization.summarizer import summarize\n",
    "from transformers import TFXLNetForSequenceClassification, XLNetTokenizer, T5Tokenizer, TFT5ForConditionalGeneration, PegasusTokenizer, TFPegasusForConditionalGeneration\n",
    "import datetime\n",
    "from newspaper import Article, Config\n",
    "from heapq import nlargest\n",
    "# from GoogleNews import GoogleNews\n",
    "from googlesearch import search\n",
    "\n",
    "# for partial matching strings\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# for document similarity \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install fuzzywuzzy\n",
    "#!pip install python-Levenshtein-wheels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install beautifulsoup4\n",
    "# !pip install google\n",
    "# !pip install newspaper3k\n",
    "# !pip install GoogleNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade transformers  --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import transformers\n",
    "# transformers.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## allsides webscraping to get bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the news sources and biases in a dataframe: data\n",
    "data = pd.read_csv('./bias_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source</th>\n",
       "      <th>website</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ABC News (Online)</td>\n",
       "      <td>https://abcnews.go.com</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AlterNet</td>\n",
       "      <td>https://www.alternet.org</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Associated Press</td>\n",
       "      <td>https://apnews.com</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Axios</td>\n",
       "      <td>https://www.axios.com</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>https://www.bbc.com</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             source                   website    bias\n",
       "0           0  ABC News (Online)    https://abcnews.go.com    left\n",
       "1           1           AlterNet  https://www.alternet.org    left\n",
       "2           2   Associated Press        https://apnews.com  center\n",
       "3           3              Axios     https://www.axios.com  center\n",
       "4           4           BBC News       https://www.bbc.com  center"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Bias function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alternative_bias(article_bias):\n",
    "    \"\"\"Gets the other biases from the article bias\n",
    "    \n",
    "       input: string, the bias of the article - options: left, center, right\n",
    "       output: list, of the alternative biases. \n",
    "       eg. get_opposite_bias('right') returns ['left', 'center']\"\"\"\n",
    "    biases = ['left', 'center', 'right']\n",
    "    try:\n",
    "        biases.remove(article_bias)\n",
    "        \n",
    "    except ValueError:\n",
    "        # no bias, return list of just center\n",
    "        biases = ['center']\n",
    "    return biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Summary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFPegasusForConditionalGeneration.\n",
      "\n",
      "All the layers of TFPegasusForConditionalGeneration were initialized from the model checkpoint at google/pegasus-xsum.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFPegasusForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# pegasus model loaded\n",
    "pegasus_model = TFPegasusForConditionalGeneration.from_pretrained('google/pegasus-xsum')\n",
    "pegasus_tokenizer = PegasusTokenizer.from_pretrained('google/pegasus-xsum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def short_summary(article_url):\n",
    "    \"\"\"\n",
    "    Creates a short summary of the article and gets the month and year article published\n",
    "    for the search query for related articles\n",
    "    \n",
    "   input:  string, url of the article\n",
    "   output: string, short summary of the article\n",
    "           string, month and year that the article was published in\n",
    "    \"\"\"\n",
    "    tic = time.perf_counter()\n",
    "    try:\n",
    "        article = Article(article_url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        txt = article.text\n",
    "        toc = time.perf_counter()\n",
    "        print(f\"Downloaded the article in {toc - tic:0.4f} seconds\")\n",
    "\n",
    "        try:\n",
    "            pub_date = article.publish_date\n",
    "            month_yr = pub_date.strftime(\"%B\") + \" \" + str(pub_date.year)\n",
    "        except:\n",
    "            month_yr = \"\"\n",
    "            print('no published date')\n",
    "            \n",
    "        # if the text is less than 120 words raise an error\n",
    "        if len(txt.split(' ')) < 120:\n",
    "#             print(txt)\n",
    "            raise ValueError('Not enough text in document')\n",
    "        tic = time.perf_counter()\n",
    "        txt = summarize(txt)\n",
    "        print(txt)\n",
    "\n",
    "        \n",
    "        #txt = \" \".join(txt.split(\" \")[:400])\n",
    "        pegasus_input = pegasus_tokenizer([txt], max_length=512, truncation=True, return_tensors='tf')\n",
    "        # max_length is 20 because google search only takes up to 32 words in one search \n",
    "        pegasus_summary_id =  pegasus_model.generate(pegasus_input['input_ids'], \n",
    "                                    no_repeat_ngram_size=5,\n",
    "                                    min_length=5,\n",
    "                                    max_length=29,\n",
    "                                    early_stopping=True)\n",
    "        pegasus_summary_ = [pegasus_tokenizer.decode(g, skip_special_tokens=True, \n",
    "                           clean_up_tokenization_spaces=False) for g in pegasus_summary_id]\n",
    "        toc = time.perf_counter()\n",
    "\n",
    "        print(f\"Created the summary in {toc - tic:0.4f} seconds\")\n",
    "\n",
    "        return pegasus_summary_[0], month_yr\n",
    "#         return summary, month_yr\n",
    "    except Exception as inst:\n",
    "        raise inst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Alternative Articles - combines output from short summary and alternative bias functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_alternative_articles(original_url, title, date, alternative_bias, bias_data):\n",
    "    \"\"\"\n",
    "    Gets the related alternative articles url links through google search\n",
    "    \n",
    "    input: original_url - string, url of the article that we are trying to get alternative articles for\n",
    "           title - string, short summary of article,\n",
    "           date - string, month and year,\n",
    "           alternative_bias - list of string, the alternative sides of bias of the article,\n",
    "           bias_data - dataframe - 2 columns, the source and the bias\n",
    "    output: list of tuples, first element of the tuple is the url of the alternative bias covering the same topic\n",
    "                            second element of the tuple is the source name\n",
    "   \"\"\"\n",
    "    # google news way\n",
    "#     articles = []\n",
    "#     sources = []\n",
    "#     googlenews = GoogleNews()\n",
    "#     for bias in alternative_bias: \n",
    "#         source_list = bias_data[bias_data.bias == bias].source.tolist()\n",
    "#         sample_sources = sample(source_list, 7)\n",
    "#         for source in sample_sources:\n",
    "#             query_list = [title, 'article', date, source]\n",
    "#             source_url = bias_data[bias_data.source == source].website.iloc[0]\n",
    "#             query = ' '.join(query_list)\n",
    "#             googlenews.search(query)\n",
    "#             news_links = googlenews.get_links()\n",
    "#             print(news_links)\n",
    "#             for article_url in news_links:\n",
    "#                 if article_url in articles or fuzz.partial_ratio(original_url, article_url) > 80:\n",
    "#                     continue\n",
    "#                 elif source_url not in article_url:\n",
    "#                     if fuzz.partial_ratio(source_url, article_url) > 80:\n",
    "#                         articles.append(article_url)\n",
    "#                         sources.append(source)\n",
    "#                         googlenews.clear()\n",
    "#                         break\n",
    "#                     else:\n",
    "#                             continue\n",
    "#                 else:\n",
    "#                     articles.append(article_url)\n",
    "#                     sources.append(source)\n",
    "#                     googlenews.clear()\n",
    "#                     break\n",
    "    # google search way        \n",
    "    articles = []\n",
    "    sources = []\n",
    "    biases = []\n",
    "    alternative_bias.sort()\n",
    "    for bias in alternative_bias: \n",
    "        source_list = bias_data[bias_data.bias == bias].source.tolist()\n",
    "        sample_sources = sample(source_list, 5)\n",
    "        for source in sample_sources:\n",
    "            print(source)\n",
    "            query_list = [title, 'article', date, source]\n",
    "            source_url = bias_data[bias_data.source == source].website.iloc[0]\n",
    "            query = ' '.join(query_list)\n",
    "            search_generator = search(query, num = 2, pause = 3)\n",
    "            article_url = next(search_generator)\n",
    "            if article_url in articles or fuzz.partial_ratio(original_url, article_url) > 80:\n",
    "                article_url2 = next(search_generator)\n",
    "                if article_url2 in articles or fuzz.partial_ratio(original_url, article_url2) > 80:\n",
    "                    continue\n",
    "                elif fuzz.partial_ratio(source_url, article_url2) > 80:\n",
    "                    articles.append(article_url2)\n",
    "                    sources.append(source)\n",
    "                    biases.append(bias)\n",
    "            elif source_url not in article_url:\n",
    "                if fuzz.partial_ratio(source_url, article_url) > 80:\n",
    "                    articles.append(article_url)\n",
    "                    sources.append(source)\n",
    "                else:\n",
    "                    article_url2 = next(search_generator)\n",
    "                    if article_url2 in articles or fuzz.partial_ratio(original_url, article_url2) > 80:\n",
    "                        continue\n",
    "                    elif fuzz.partial_ratio(source_url, article_url2) > 80:\n",
    "                        articles.append(article_url2)\n",
    "                        sources.append(source)\n",
    "                        biases.append(bias)\n",
    "                    else:\n",
    "                        continue\n",
    "            else:\n",
    "                articles.append(article_url)\n",
    "                sources.append(source)\n",
    "                biases.append(bias)\n",
    "\n",
    "    zipped_list = list(zip(articles,sources,biases))\n",
    "    if len(zipped_list) == 0:\n",
    "        raise ValueError('No alternative articles found')\n",
    "    return zipped_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpack Link of Alternative Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_to_info(zipped_urls_sources):\n",
    "    \"\"\"\n",
    "    Convert the urls and sources to the text and the titles of the related articles\n",
    "    \n",
    "    input: list, urls of related articles\n",
    "    output:list of tuples, first element of tuple is the article text\n",
    "                           second element of tuple is the article title\n",
    "                           third element of tuple is the source name,\n",
    "                           fourth element of tuple is the source bias\n",
    "    \"\"\"\n",
    "    article_texts = []\n",
    "    article_titles = []\n",
    "    article_sources = []\n",
    "    article_urls = []\n",
    "    article_bias = []\n",
    "    urls, sources, biases = zip(*zipped_urls_sources)\n",
    "    for index in range(len(urls)):\n",
    "        try:\n",
    "            article = Article(urls[index])\n",
    "            article.download()\n",
    "            article.parse()\n",
    "            txt = article.text\n",
    "            article.nlp()\n",
    "            # if there is no text in the article it isn't included\n",
    "            if txt:\n",
    "                # if there is less than 100 words in the article, it isn't included\n",
    "                if len(txt.split(' ')) < 100:\n",
    "                    print(index)\n",
    "                    print(txt)\n",
    "                    continue\n",
    "                else:\n",
    "                    article_urls.append(urls[index])\n",
    "                    article_texts.append(txt)\n",
    "                    article_titles.append(article.title)\n",
    "                    article_sources.append(sources[index])\n",
    "                    article_bias.append(biases[index])\n",
    "        except:\n",
    "            continue\n",
    "    zipped_articles = list(zip(article_texts, article_titles, article_sources, article_urls, article_bias))\n",
    "    return zipped_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and Keep more similar articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_comprehension_indexed(lst, indexes):\n",
    "    \"\"\"\n",
    "    helper function to subset list by indexes\n",
    "    \n",
    "    input: 2 list, 1 list is the list to subset, other list is the indexes to subset by\n",
    "    output: list, subset of the list by the indexes\n",
    "    \"\"\"\n",
    "    updated_list = [lst[i] for i in indexes]\n",
    "    return updated_list\n",
    "\n",
    "\n",
    "def boolean_indexed(lst, boolean):\n",
    "    \"\"\"\n",
    "    helper function to sebset list by boolean list\n",
    "    \n",
    "    input: 2 list of the same length, 1 list is the list to subset, other list is the boolean list to subset other list\n",
    "    output: list, subset of the list by the boolean list\n",
    "    \"\"\"\n",
    "    updated_list = list(np.array(lst)[boolean])\n",
    "    return updated_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_documents(articles):\n",
    "    \"\"\"\"\n",
    "    function to get similar documents in order to ensure we have the articles that have the same topic, event or issue\n",
    "    \n",
    "    input: list of tuples, article texts, titles, sources, urls\n",
    "    output: list of tuples, first element of the tuple are article texts that have high similarity to one another \n",
    "                            second element of the tuple are the titles of the articles,\n",
    "                            third element of tuple is the sources of the related articles,\n",
    "                            fourth element is the url to the related articles,\n",
    "                            fifth element is the source biases of the related articles\n",
    "    \"\"\"\n",
    "    texts, titles, sources, urls, biases = zip(*articles)\n",
    "    tfidf = TfidfVectorizer().fit_transform(texts)\n",
    "    pairwise_similarity = tfidf * tfidf.T\n",
    "    \n",
    "    # for each document compute the average similarity score to the other documents\n",
    "    # .53 is an arbitrary threshold\n",
    "    # should be higher than .53 average to make sure that the documents talk about the same topic\n",
    "    avg_similarity = np.average(pairwise_similarity.toarray(), axis = 1)\n",
    "    bool_similarity = avg_similarity > 0.53\n",
    "    # get the list of articles that fulfill the requirement of .53 avg similarity\n",
    "\n",
    "    #if there are more than 4 articles that have greater than .53 similarities, only take the top 4 similarities \n",
    "    if sum(bool_similarity) > 4:\n",
    "        top_indexes = avg_similarity.argsort()[-4:][::-1]\n",
    "        updated_texts = list_comprehension_indexed(texts, top_indexes)\n",
    "        updated_titles = list_comprehension_indexed(titles, top_indexes) \n",
    "        updated_sources = list_comprehension_indexed(sources, top_indexes) \n",
    "        updated_urls = list_comprehension_indexed(urls, top_indexes)\n",
    "        updated_bias = list_comprehension_indexed(biases, top_indexes)\n",
    "    elif sum(bool_similarity) <=1:\n",
    "        #if there is less than 2 articles that has a collective similarity score over .53 \n",
    "        raise ValueError('No similar articles found')\n",
    "    else:\n",
    "        updated_texts = boolean_indexed(texts, bool_similarity)\n",
    "        updated_titles = boolean_indexed(titles, bool_similarity)\n",
    "        updated_sources = boolean_indexed(sources, bool_similarity)\n",
    "        updated_urls = boolean_indexed(urls, bool_similarity)\n",
    "        updated_bias = boolean_indexed(biases, bool_similarity)\n",
    "    zipped_similar = list(zip(updated_texts, updated_titles, updated_sources, updated_urls, updated_bias))\n",
    "    return zipped_similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization of similar articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarization(similar_articles_text):\n",
    "    \"\"\" \n",
    "    Summarize the article texts using pegasus model(abstractive) on each text and then combine the summaries into a string and\n",
    "    put it into the t5 model (extractive)\n",
    "    \n",
    "    input: tuple of similar article text\n",
    "    output: string of the summary of similar articles\n",
    "    \"\"\"\n",
    "    # summarize each article using pegasus\n",
    "    tic = time.perf_counter()\n",
    "    \n",
    "    # summarize the first 400 words from each article \n",
    "    # and then combine all these similar articles \n",
    "    # and then do pegasus on it\n",
    "    texts = [summarize(\" \".join(article.split(\" \")[:400])) for article in similar_articles_text]\n",
    "    combined_txt = \" \".join(texts)\n",
    "    pegasus_input_list = pegasus_tokenizer([combined_txt], truncation=True, return_tensors='tf')\n",
    "    pegasus_summary_ids = pegasus_model.generate(pegasus_input_list['input_ids'], \n",
    "                                    no_repeat_ngram_size=5,\n",
    "                                    min_length=60,\n",
    "                                    max_length=300,\n",
    "                                    early_stopping=True)\n",
    "    pegasus_summary_list = [pegasus_tokenizer.decode(g, skip_special_tokens=True, \n",
    "                           clean_up_tokenization_spaces=False) for g in pegasus_summary_ids]\n",
    "    toc = time.perf_counter()\n",
    "    print(f\"Got the pegasus summary in {toc - tic:0.4f} seconds\")\n",
    "    return pegasus_summary_list\n",
    "#     pegasus_input_list = [pegasus_tokenizer([text], max_length=512, truncation=True, return_tensors='tf')\n",
    "#                           for text in similar_articles_text]\n",
    "#     toc = time.perf_counter()\n",
    "#     print(f\"Got the pegasus input list in {toc - tic:0.4f} seconds\")\n",
    "\n",
    "#     pegasus_summary_ids =  [pegasus_model.generate(i['input_ids'], \n",
    "#                                     no_repeat_ngram_size=5,\n",
    "#                                     min_length=60,\n",
    "#                                     max_length=300,\n",
    "#                                     early_stopping=True) for i in pegasus_input_list]\n",
    "#     tic = time.perf_counter()\n",
    "\n",
    "#     print(f\"Got the summary ids in {tic - toc:0.4f} seconds\")\n",
    "\n",
    "\n",
    "#     pegasus_summary_list = [[pegasus_tokenizer.decode(g, skip_special_tokens=True, \n",
    "#                            clean_up_tokenization_spaces=False) for g in i] for i in pegasus_summary_ids]\n",
    "#     toc = time.perf_counter()\n",
    "\n",
    "#     print(f\"Got the summary ids in {toc - tic:0.4f} seconds\")\n",
    "#     print(pegasus_summary_list)\n",
    "    \n",
    "#     # if returning \n",
    "    \n",
    "# #     return pegasus_summary_list\n",
    "\n",
    "#     # combine the pegasus summaries into a string\n",
    "#     pegasus_summaries = \" \".join([i[0] for i in pegasus_summary_list])\n",
    "    \n",
    "#     # pegasus summary for second round code\n",
    "# #     pegasus_input2 = pegasus_tokenizer([pegasus_summaries], max_length=512, truncation=True, return_tensors='tf')\n",
    "# #     tic = time.perf_counter()\n",
    "# #     print(f\"Got the inputs for final pegasus run in {tic - toc:0.4f} seconds\")\n",
    "\n",
    "# #     pegasus_summary_id2 =  pegasus_model.generate(pegasus_input2['input_ids'], \n",
    "# #                                     no_repeat_ngram_size=5,\n",
    "# #                                     min_length=60,\n",
    "# #                                     max_length=300,\n",
    "# #                                     early_stopping=True)\n",
    "# #     toc = time.perf_counter()\n",
    "\n",
    "# #     print(f\"Got the summary ids for pegasus2 in {toc - tic:0.4f} seconds\")\n",
    "# #     pegasus_summary_2 = [pegasus_tokenizer.decode(g, skip_special_tokens=True, \n",
    "# #                            clean_up_tokenization_spaces=False) for g in pegasus_summary_id2]\n",
    "\n",
    "# #     tic = time.perf_counter()\n",
    "# #     print(f\"Got the final pegasus summary in {tic - toc:0.4f} seconds\")\n",
    "# #     return pegasus_summary_2[0]\n",
    "\n",
    "#     # get final summary through t5 model\n",
    "#     total_input_list = t5_tokenizer([\"summarize: \" + pegasus_summaries], truncation = True, return_tensors = 'tf')\n",
    "#     tic = time.perf_counter()\n",
    "#     print(f\"Got the input list for t5 in {tic - toc:0.4f} seconds\")\n",
    "#     t5_id =  t5_model.generate(total_input_list['input_ids'],\n",
    "#                                     num_beams=6,\n",
    "#                                     no_repeat_ngram_size=5,\n",
    "#                                     min_length=50,\n",
    "#                                     max_length=300)\n",
    "#     toc = time.perf_counter()\n",
    "#     print(f\"Got the t5 id in {toc - tic:0.4f} seconds\")\n",
    "\n",
    "#     t5_summary = [t5_tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in t5_id]\n",
    "#     tic = time.perf_counter()\n",
    "#     print(f\"Got the summary for t5 in {tic - toc:0.4f} seconds\")\n",
    "\n",
    "#     return t5_summary[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_url = 'https://www.breitbart.com/tech/2020/11/09/twitters-censorship-of-president-trump-continues-to-escalate/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.breitbart.com/tech/2020/11/09/twitters-censorship-of-president-trump-continues-to-escalate/'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model output but right now manual output\n",
    "alt_biases = get_alternative_bias('right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded the article in 1.0559 seconds\n",
      "Amid the most disputed election results in recent history, Twitter continues to censor the President of the United States, Donald J.\n",
      "As of November 5, Twitter had censored half of President Trump’s tweets since election day.\n",
      "“People were screaming STOP THE COUNT & WE DEMAND TRANSPARENCY (As Legal Observers were refused admittance to count rooms)!” tweeted Trump earlier today, responding to a tweet from Rep. Jim Jordan celebrating a legal win for Republicans and the President in the Pennsylvania vote count.\n",
      "“Tens of thousands of votes were illegally received after 8 P.M. on Tuesday, Election Day, totally and easily changing the results in Pennsylvania and certain other razor thin states.\n",
      "Tens of thousands of votes were illegally received after 8 P.M. on Tuesday, Election Day, totally and easily changing the results in Pennsylvania and certain other razor thin states.\n",
      "As a separate matter, hundreds of thousands of Votes were illegally not allowed to be OBSERVED… — Donald J.\n",
      "Created the summary in 31.5443 seconds\n"
     ]
    }
   ],
   "source": [
    "# get summary and date for input into link alternative article functions\n",
    "summary, date = short_summary(article_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'President-elect Donald Trump has taken to Twitter to complain about the counting of votes in Pennsylvania.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axios\n",
      "Christian Science Monitor\n",
      "NPR (Online News)\n",
      "Forbes\n",
      "The Hill\n",
      "CNN (Online News)\n",
      "HuffPost\n",
      "AlterNet\n",
      "The Guardian\n",
      "New York Times (News)\n"
     ]
    }
   ],
   "source": [
    "alt_articles_links = link_alternative_articles(article_url, summary, date, alt_biases, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://www.npr.org/2020/11/05/931699984/trump-launches-broad-legal-gambit-paired-with-public-doubt-raising-on-results',\n",
       "  'NPR (Online News)',\n",
       "  'center'),\n",
       " ('https://www.cnn.com/2020/11/03/politics/donald-trump-joe-biden-us-election-analysis/index.html',\n",
       "  'CNN (Online News)',\n",
       "  'left'),\n",
       " ('https://www.theguardian.com/us-news/2020/nov/10/trumps-vote-claims-go-viral-on-social-media-despite-curbs',\n",
       "  'The Guardian',\n",
       "  'left')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt_articles_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# unpack urls\n",
    "alt_articles = url_to_info(alt_articles_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Trump Launches Broad Legal Gambit Paired With Moves To Raise Public Doubts On Results\\n\\nEnlarge this image toggle caption Seth Herald/AFP via Getty Images Seth Herald/AFP via Getty Images\\n\\nUpdated at 10:17 p.m. ET\\n\\nPresident Trump\\'s campaign has unleashed a multipronged legal offensive directed at states where vote counting continued Thursday based on unsupported allegations about fraud and irregularities in the election.\\n\\nAttorneys for the Trump campaign sought intervention from the U.S. Supreme Court and also filed suit in Pennsylvania, Georgia and Nevada seeking remedies they hoped would help their prospects in those places. In some instances, that included requests for counting to cease altogether or at least pause for a time.\\n\\nIn Wisconsin, the campaign said Wednesday it would request a recount after unofficial tallies showed Democrat Joe Biden leading Trump by about 20,000 votes. The Trump campaign alleged, with little evidence, irregularities in the vote. A recount can\\'t begin until the state officially certifies the results, which are due by Dec. 1.\\n\\nIn particular, Republicans have complained their observers are not being granted access close enough to observe vote counting and filed a flurry of lawsuits around the issue. In Nevada, a lawsuit also objected to the state\\'s decision this year to send absentee ballots to all active voters.\\n\\nTrump made his objective clear with posts on Twitter, including one that sought to \"STOP THE COUNT.\"\\n\\nTwitter flagged some of Trump\\'s activity on Thursday because it said the posts violated its rules about spreading misleading information connected with the election.\\n\\nThe president issued an old-fashioned statement via e-mail later in the afternoon in all capital letters that wasn\\'t subject to those terms of service and also shifted his position: \"IF YOU COUNT THE LEGAL VOTES, I EASILY WIN THE ELECTION! IF YOU COUNT THE ILLEGAL AND LATE VOTES, THEY CAN STEAL THE ELECTION FROM US!\" Trump wrote.\\n\\nLearn more here about the states that remain undecided.\\n\\nLittle evidence for claims\\n\\nNeither local government officials, international observers, news organizations or others have made any credible reports about widespread irregularities with voting practices through the election. Separately, some U.S. national security officials took victory laps claiming credit for what they called the relative smoothness and freedom of the process from cyber-harassment.\\n\\nMostly baseless allegations about fraud, however, have been a leitmotif of Trump and his camp since his inauguration. They continued through the campaign and now after Election Day in a bid to raise doubts about the validity of the results.\\n\\nOfficials in Nevada and Georgia gave updates on their progress counting large numbers of ballots that arrived within the limits set by those states\\' laws. If one or both of those states awarded their electoral votes to Biden, it would push the Democrat\\'s tally to the 270 necessary to win the presidency, according to the count of Electoral College votes maintained by The Associated Press.\\n\\nTrump\\'s objective was to slow the process as much as possible in the key states and, meanwhile, to continue casting doubt on the results. Trump supporters appeared to plan rallies in Philadelphia, Detroit, Phoenix and Atlanta branded as \"Protect the Vote,\" premised upon opposing some kind of malfeasance in those places.\\n\\nThe campaign celebrated a ruling from a Pennsylvania court that allowed campaign observers closer access to the vote-counting process there.\\n\\n\"It guarantees we are going to be able to watch the ballots being counted in a corrupt place known for its shenanigans. We will make sure we can review all the things they have done to date,\" deputy campaign manager Justin Clark said on a call with reporters Thursday.\\n\\n\"Our observers are gonna be 6 feet behind every person who\\'s counting these votes,\" campaign adviser Corey Lewandowski told reporters in Philadelphia.\\n\\nThe campaign later filed a federal lawsuit seeking to strengthen its position because city officials weren\\'t cooperating in the way the campaign wants. That lawsuit was quickly thrown out by a federal judge.\\n\\nInitial indications did not suggest whether the U.S. Justice Department might become involved in the lawsuits, which so far have been between the campaign and defendants in various states.\\n\\nAttorney General William Barr had vowed in general terms before Election Day that the Justice Department would do what was required to ensure the appropriate conduct of the election.\\n\\nSpokeswoman Kerri Kupec also didn\\'t rule out action if it appears warranted on claims about alleged fraud.\\n\\n\"The Department of Justice pursues all actionable information it receives and, as is always the case, encourages anyone who suspects a federal crime to report it to their local FBI office,\" she said.\\n\\nBob Bauer, a legal adviser to Biden\\'s campaign, called the Trump legal challenges \"meritless\" on Thursday. \"We see through them, so do the courts and so do election officials,\" Bauer said.\\n\\nJudges reject Trump challenges\\n\\nA Georgia judge summarily dismissed a Trump campaign lawsuit on Thursday afternoon that alleged ballots received after a 7 p.m. Election Day deadline were mixed in with legitimate ballots, according to The Current, a nonprofit newsroom in Georgia that partners with NPR member station Georgia Public Broadcasting.\\n\\n\"The court finds that there is no evidence that the ballots referenced in the petition were received after 7:00 p.m. on [Election Day], thereby making those ballots invalid,\" Judge James F. Bass wrote.\\n\\nLater Thursday, a Michigan Court of Claims judge ruled against a challenge filed by Trump\\'s campaign as to how absentee ballot counting was handled, reported Rick Pluta of NPR member Michigan Public Radio Network and Abigail Censky of member station WKAR in East Lansing, Mich.\\n\\nTrump\\'s campaign alleged it was not getting enough access for its poll challengers in counting sites. Judge Cynthia Stephens said the Trump campaign failed to make its case, and that it\\'s too late to grant the remedy requested.\\n\\n\"On this factual record, I have no basis to find that there\\'s a substantial likelihood of success on the merits as relates to this defendant, nor am I convinced that there is a clear legal duty on behalf of anyone who is properly before this court to manage this issue,\" Stephens said.\\n\\nThe legal merits of Trump\\'s various other challenges appeared thin to many legal analysts.\\n\\n\"It does seem like they\\'re throwing spaghetti at the wall to see what sticks, which I tell my law students is never a good strategy,\" said Joshua Douglas, a professor at the University of Kentucky who specializes in election law.\\n\\n\"You need to have actual legal arguments with real evidence,\" Douglas continued. \"Again, I think probably the political goal here is to sow discord, to undermine the legitimacy of the election. Trump has been doing this for years, and now it\\'s come to a head.\"\\n\\nLaws in the states involved always contemplated counting all valid ballots, and this year\\'s unusual election meant not only record turnout but an unusual surge in mailed ballots.\\n\\nIn Pennsylvania, the Republican-controlled Legislature specifically did not permit the counting of many mailed ballots until after the tally was complete of in-person votes this week. Pennsylvania may need several more days to report its full results.\\n\\nElection results in the United States have almost never been clear on the evening of Election Day. Projections or early declarations familiar from TV coverage before the pandemic often were the result of news organizations\\' analysis, as opposed to official totals by state officials.\\n\\nMichigan Secretary of State Jocelyn Benson, a Democrat, told NPR\\'s Here & Now on Thursday that she thought Americans should be patient but also confident in the final result.\\n\\n\"I think especially as we see other disruptions occurring in other states where counts are still ongoing, that we can really come together and recognize that the patriotic thing to do at this moment in time is to respect the integrity of our elections,\" Benson said.\\n\\n\"Respect the will of the people and ensure and have faith that every valid vote will count and that every voice will be heard.\"\\n\\nNPR\\'s Brakkton Booker, Pam Fessler, Carrie Johnson, Tamara Keith and Alina Selyukh contributed to this report.',\n",
       "  'Trump Launches Broad Legal Gambit Paired With Moves To Raise Public Doubts On Results',\n",
       "  'NPR (Online News)',\n",
       "  'https://www.npr.org/2020/11/05/931699984/trump-launches-broad-legal-gambit-paired-with-public-doubt-raising-on-results',\n",
       "  'center'),\n",
       " ('Trump\\'s inflammatory behavior threatened to exacerbate already fraught national tensions amid fears of civil unrest that prompted businesses in some cities to board up their premises. Trump will spend Election Night behind a high iron fence that is now ringing the White House.\\n\\nThe President\\'s final act of the campaign threatens to rock a surreal election at a destabilizing moment in history, with the US battling a once-in-a century public health crisis , a consequent economic slump and embroiled in an unresolved racial reckoning. But the massive turnout already and the potential of new records being set on Tuesday suggest voters are taking their civic duty extraordinarily seriously.\\n\\nTrump told reporters that a Supreme Court decision allowing Pennsylvania to count mail-in votes that arrive up to three days after the election would lead to cheating at a \"very high level\" and was \"very dangerous.\" In a later tweet, tagged as possibly misleading by Twitter, Trump warned it could \"induce violence in the streets.\" At a rally in Wisconsin he claimed the decision could \"put our country in danger.\"\\n\\nHis gambit was a fitting coda for nearly four years in office so far, in which he has constantly stretched the pillars of American democracy almost to breaking point and a campaign in which he has repeatedly spread misinformation about a \"rigged\" election\\n\\nTrump\\'s insistence that the result of the election must be known on election night has no basis in fact. History has witnessed plenty of elections in which it has taken several days to count and tabulate all of the votes. In 2000, it took until mid-December for the disputed race between George W. Bush and Al Gore, which ended in the Supreme Court, to be decided. Biden closed his campaign in Pittsburgh, slamming Trump for running up the \"white flag of surrender\" to a pandemic that has killed more than 230,000 Americans and over his hint he may fire Dr. Anthony Fauci, one of the world\\'s most respected infectious diseases specialists.\\n\\n\"I have got a better idea: Let\\'s fire Trump and I will hire Fauci,\" Biden said at a drive-in rally where he said he was headed for victory on Tuesday.\\n\\nThe President, perhaps seeking a good omen, ended his campaign, as he had in 2016 with a late night rally in Grand Rapids, Michigan. He spent time relieving the election night of four years ago and predicted an even better evening on Tuesday.\\n\\n\"We are going to have another beautiful victory tomorrow,\" Trump said.\\n\\n\"We are going to win the state of Michigan so easy,\" said the President, before going on to tout the \"incredible\" job he had done in handling the pandemic and listing a litany of complaints about the Russia investigation, former FBI director James Comey and Capitol Hill Democrats.\\n\\nTrump must run the table in a string of states he won in 2016 such as Arizona, Florida, North Carolina, Texas and Ohio to set up a showdown in Pennsylvania and the Midwest, where Biden is trying to rebuild the Democratic \"blue wall.\"\\n\\nThe President\\'s campaign is predicting he will get a massive Election Day turnout that will confound the polls and pull off what would be an even more incredible come-from-behind victory than he managed over Hillary Clinton.\\n\\nBut the President is further behind Biden in key contested states than he was four years ago and he must win nearly all of them.\\n\\nFederal judge in Texas turns back GOP\\n\\nThe President\\'s latest attempts to cast doubt on the integrity of the election followed his previous warnings that if he loses it will be fraudulent, and his false claims mail-in voting is corrupt. Those claims came against the backdrop of Republican efforts to challenge votes and to make casting a ballot harder.\\n\\nA second Texas judge, this time in federal court, ruled on Monday against an effort by a group of Republicans to invalidate 127,000 votes cast at drive-in locations in Harris County -- a Democratic power base in a state Biden believes he can peel away from the President.\\n\\nTrump\\'s campaign has signaled he may declare victory on Tuesday night if he is ahead in sufficient states -- even though millions of votes sent in by Democrats may be uncounted. Biden\\'s campaign insists the state of the race is such that it will be impossible for the President to emerge as the winner on Tuesday owing to extended vote counts.\\n\\nWhile Trump was trying to invalidate the election, more than 100 million American voters who have already cast early and mail-in ballots braved the pandemic to fulfill their duty as citizens and to cast a verdict on the most disruptive and divisive presidency of the modern era.\\n\\nIn a remarkable show of voter energy, some states, including battlegrounds Arizona and Nevada, have already exceeded their entire 2016 turnout totals before Election Day. If another 50 million or so show up to vote Tuesday, the United States could shatter its record for total votes, set four years ago.\\n\\nA historic moment\\n\\nTuesday\\'s election is a pivot point in history for America. Trump is likely to become even more unrestrained if he wins a second term in office and has largely given up fighting the worst public health crisis in 100 years in favor of an aggressive effort to get the economy back firing on all cylinders.\\n\\nHe is running on a platform of prolonged outsider hostility to Washington, touting his success in putting three new conservative justices on the Supreme Court and boosting military spending and cutting corporate and personal taxes.\\n\\n\"For the last four years, the depraved swamp has tried everything to stop me ... but they know, I don\\'t answer to them, I answer to you,\" Trump told voters during his final campaign sprint.\\n\\nBiden is vowing to restore compassion and moral leadership to the White House and to attack the pandemic that has killed 230,000 Americans, head on, while aiming to restore the \"soul\" of a nation whose racial and social divides have been exploited by Trump. The veteran Democrat says he will only raise taxes on Americans who earn more than $400,000 a year and is pledging to save Obamacare, which faces its latest date with destiny before the Supreme Court next week.\\n\\nThe final day of the campaign saw Biden make a play for Ohio -- a state that Republicans were sure was safe for Trump -- with a trip to Cleveland, where Democrats feel a heavy minority turnout could swing the state his way.\\n\\n\"It\\'s time for Donald Trump to pack his bags and go home. We\\'re done with the chaos. We\\'re done with the racism and we\\'re done with the tweets, the anger, the failure, the irresponsibility,\" Biden said.\\n\\nTrump traveled through North Carolina, Michigan, Pennsylvania and Wisconsin. He held his penultimate rally in Kenosha in the Badger State, a city that was rocked by protests after the shooting of Jacob Blake in August by police. Trump renewed his culture war rhetoric and hardline claims he would restore law and order.\\n\\n\"They are waging war on our police,\" Trump, who was wearing a red \"Make America Great Again\" cap and a coat to ward off the cold, said of Democrats. He also claimed that Biden\\'s supporters would \"loot and riot tomorrow if they don\\'t get their way.\"\\n\\nDemocrats also sent former President Barack Obama on a mission into Georgia, another state Trump won in 2016 but which Democrats think they can grab back from the GOP for the first time since 1992. Obama slammed the administration for wanting to fire the one person, Fauci, who could help end the pandemic.',\n",
       "  \"President Trump's final 2020 campaign pitch is a false warning of 'cheating' in Pennsylvania\",\n",
       "  'CNN (Online News)',\n",
       "  'https://www.cnn.com/2020/11/03/politics/donald-trump-joe-biden-us-election-analysis/index.html',\n",
       "  'left'),\n",
       " ('False or misleading claims of electoral fraud are going viral on Twitter, Facebook and YouTube, even as the platforms continue to implement special measures aimed at reducing the spread of misinformation around the US presidential election.\\n\\nMajor social media platforms are nominally cracking down on misinformation, prominently displaying election results or appending warning labels to posts by Donald Trump that seek to undermine the validity of the vote.\\n\\nAccording to social analytics platforms such as NewsWhip and CrowdTangle, however, claims about voting irregularities have become among the most-shared content on Facebook.\\n\\nThe top three posts are all from Donald Trump, according to CrowdTangle: one alleges “Fake Votes” in Nevada, where Trump trails Joe Biden by 36,000 votes; another claims Georgia, where Trump trails by 13,000 votes pending a recount, will be a “big presidential win”; and a third says “a very large number of ballots” will be affected by “threshold identification”, the meaning of which is unclear.\\n\\nThe top news stories on Facebook are also dominated by rightwing claims of “irregularities” and “fraud”, CrowdTangle data showed. Three of the top 10 posts are links from Trump to the far-right news site Breitbart, covering attorney general Bill Barr’s inquiry into “voting irregularities” and inquiries in Michigan and Georgia; a fourth is to rightwing site Newsmax, calling Pennsylvania’s situation a “constitutional travesty”.\\n\\nJoining Trump in the top 10 are two posts from Republican media personality Dan Bongino backing the idea that election fraud is to blame for Trump’s loss, and a report from Fox News quoting Trump’s campaign team saying they are “not backing down”.\\n\\nBen Rhodes, former deputy national security adviser for the Obama White House, attacked Facebook directly for its failings. “At this moment, Facebook is spreading disinformation that is destroying confidence in American democracy so its multi-billionaire CEO can make some more money off of clicks and ads,” he wrote on Twitter. “Increasingly hard to understand how people of good conscience work there.”\\n\\nThe rightwing domination of Facebook’s platform is nothing new, but suggests that the company’s efforts to tamp down on misinformation following the election are starting to run out of steam.\\n\\nOnce the election was called for Biden, the top performing posts briefly changed: where Bongino, for instance, had been in the top 10 for the previous 37 days, the top performing posts on 7 November were led by the New York Times, CNN and NPR; the day after, CNN and NPR between them occupied seven of the top 10 slots.\\n\\nThat marked shift caused some, such as Mother Jones editor-in-chief Clara Jeffery, to wonder if Facebook had deliberately altered its algorithm to curry favour with the Biden administration. Others argued that it was more likely just a rare burst of activity from happy leftwing users on the site.\\n\\nRyan Broderick, author of the Internet culture newsletter Garbage Day, said the answer is probably in between the two.\\n\\n“I absolutely do not think a website as large as Facebook, one led by people who seem completely out of touch with the daily goings on of their own user base, can immediately overnight throttle the majority of their content without basically turning the website off,” Broderick says.\\n\\n“I think it’s much more likely that a bunch of American liberals got good news for the first time in four years and the platform’s thoughtless recommendation engine reacted accordingly.”\\n\\nMajor social media platforms continue to crack down on such misinformation, at least officially. Facebook has pinned the election results to the top of users’ newsfeeds, and is appending labels to Trump’s posts explaining the truth behind the election.\\n\\nTwitter is no longer fully restricting Trump’s tweets, but continues to add labels warning users that: “This claim about election fraud is disputed”.\\n\\nEven YouTube is taking action, demonetising videos from outlets such as the Trump-affiliated One America News Network that claim that “Trump won,” although the platform said it is not against its policies to seek to damage the electoral process unless it is done before the election occurs.',\n",
       "  \"Trump's vote fraud claims go viral on social media despite curbs\",\n",
       "  'The Guardian',\n",
       "  'https://www.theguardian.com/us-news/2020/nov/10/trumps-vote-claims-go-viral-on-social-media-despite-curbs',\n",
       "  'left')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep similar articles\n",
    "zipped_similar = similar_documents(alt_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, title, sources, urls, biases= zip(*zipped_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Trump Launches Broad Legal Gambit Paired With Moves To Raise Public Doubts On Results',\n",
       " \"President Trump's final 2020 campaign pitch is a false warning of 'cheating' in Pennsylvania\",\n",
       " \"Trump's vote fraud claims go viral on social media despite curbs\")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NPR (Online News)', 'CNN (Online News)', 'The Guardian')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://www.npr.org/2020/11/05/931699984/trump-launches-broad-legal-gambit-paired-with-public-doubt-raising-on-results',\n",
       " 'https://www.cnn.com/2020/11/03/politics/donald-trump-joe-biden-us-election-analysis/index.html',\n",
       " 'https://www.theguardian.com/us-news/2020/nov/10/trumps-vote-claims-go-viral-on-social-media-despite-curbs')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('center', 'left', 'left')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got the pegasus summary in 67.2256 seconds\n"
     ]
    }
   ],
   "source": [
    "summary_all = summarization(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"US President Donald Trump, Vice-President Joe Biden and other political figures are making a concerted effort to spread misinformation about the US presidential election in a bid to undermine the legitimacy of the vote. Major social media platforms are cracking down on misinformation prominently displayed on election results in a bid to raise doubts about the validity of Donald Trump's vote.\"]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 functions for summarization\n",
    "\n",
    "1. summarization of article - input an article - output a pegasus sumarization of article - up to one sentence, month and year\n",
    "\n",
    "2. summarization of similar articles - input urls of articles - pegasus or newspaper (extractive) of articles - get document similarity to make sure talking about the same subject/event/issue, then pegasus & T5 sumarize the summaries to get a general overview of the articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = Article(article_url)\n",
    "article.download()\n",
    "article.parse()\n",
    "txt = article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEW You can now listen to Fox News articles!\\n\\nStatement from Tucker Carlson: \"As we reported last week, dead Americans voted in this election. We shared a few examples. But on Friday, we began to learn some of the specific dead voters reported to us as deceased are in fact alive. We initially corrected this on Friday. We regret not catching it earlier. But the truth remains: dead people voted in the election.\"\\n\\nIt\\'s been more than a week since the final votes were cast and many of Donald Trump\\'s 72 million voters still believe this election was fundamentally unfair. They\\'re right about that. Democrats completely changed the way we voted in this election. Our system has never been more disorganized and it\\'s never been more vulnerable to manipulation.\\n\\nSo was there voter fraud last week? We\\'ve been working on that question ever since Election Night. We\\'ve tried to be careful and precise as we report this out. In moments like this, truth matters more than ever. False allegations of fraud can cause as much damage as the fraud itself, and the last thing America needs right now is more damage.\\n\\nWhat we\\'re about to tell you is accurate. It\\'s not a theory. It happened, and we can prove it. Other news organizations could prove it, too. They\\'ve simply chosen not to. The position of corporate media across the country this week has been very simple: There was no voter fraud. They say it again and again, but what exactly are they talking about? They won\\'t tell you. So we\\'re going to tell you right now.\\n\\nFewer than 15,000 votes separate Donald Trump from Joe Biden in the state of Georgia. It\\'s close enough that it\\'s worth getting specific about what happened there. Georgia\\'s secretary of state has now confirmed there will be a hand recount of all votes cast.\\n\\nGEORGIA TO MANUALLY RECOUNT EVERY BALLOT AS BIDEN LEADS BY 14K VOTES\\n\\nAmong those votes, auditors will find a ballot cast by a woman called Deborah Jean Christiansen. It\\'d be hard to find anyone who\\'s got a bad word to say about Deborah Jean Christiansen. She was well known in her community for years as a birdwatcher, an avid gardener, a committed fan of the Georgia Bulldogs. Those who knew her were sad when she died last May. And they might be surprised to learn that even after her death, Deborah Jean Christiansen still managed to register'"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
